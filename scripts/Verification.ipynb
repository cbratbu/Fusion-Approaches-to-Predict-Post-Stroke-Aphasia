{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries import * \n",
    "from getData import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    Augmentation_settings = {\n",
    "        \"Cross Validation Type\": \"kTkV\",\n",
    "        \"model\" : \"SVR\",\n",
    "        \"metric\" : \"all-metrics\", # not required anymore\n",
    "\n",
    "        \"Augment\" : False, # not implemented yet\n",
    "        # \"transform\" : True, # need to implement this now. \n",
    "\n",
    "        \"verbose\" : 0,    # dont change this. Taken care of \n",
    "        \"top_k\" : 150,\n",
    "\n",
    "        \"repeat features\" : False,\n",
    "        \"same split\" :  False, #implement false condition\n",
    "        \n",
    "        \"stratified\" : False,\n",
    "        \"data\" : \"RS\",\n",
    "        \n",
    "        \"feature reduction\" : \"pearason\",\n",
    "        \"features reduced per step\" : 1\n",
    "        # \"order\" : args.order if 'stratified' in args else None, #implement false condition\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GET = getData(Augmentation_settings)\n",
    "features, data, outputs = GET.data()\n",
    "\n",
    "num_features = 150 \n",
    "\n",
    "outputs = outputs.reshape(outputs.shape[0], 1)\n",
    "data = np.hstack((data, outputs))\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1119</th>\n",
       "      <th>1120</th>\n",
       "      <th>1121</th>\n",
       "      <th>1122</th>\n",
       "      <th>1123</th>\n",
       "      <th>1124</th>\n",
       "      <th>1125</th>\n",
       "      <th>1126</th>\n",
       "      <th>1127</th>\n",
       "      <th>1128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231838</td>\n",
       "      <td>0.105004</td>\n",
       "      <td>0.206959</td>\n",
       "      <td>0.267749</td>\n",
       "      <td>0.631039</td>\n",
       "      <td>0.194382</td>\n",
       "      <td>0.480949</td>\n",
       "      <td>0.642868</td>\n",
       "      <td>0.043913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142265</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.036892</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>0.172658</td>\n",
       "      <td>0.191546</td>\n",
       "      <td>0.044175</td>\n",
       "      <td>0.031991</td>\n",
       "      <td>0.075524</td>\n",
       "      <td>0.011537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.231838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290545</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.222755</td>\n",
       "      <td>0.163703</td>\n",
       "      <td>0.122384</td>\n",
       "      <td>0.238191</td>\n",
       "      <td>0.320355</td>\n",
       "      <td>0.171362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164165</td>\n",
       "      <td>0.108097</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.024834</td>\n",
       "      <td>0.133421</td>\n",
       "      <td>0.157720</td>\n",
       "      <td>0.271320</td>\n",
       "      <td>0.135513</td>\n",
       "      <td>0.273330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105004</td>\n",
       "      <td>0.290545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684147</td>\n",
       "      <td>0.515099</td>\n",
       "      <td>0.118176</td>\n",
       "      <td>0.234398</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>0.027732</td>\n",
       "      <td>0.428390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212825</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>0.065598</td>\n",
       "      <td>0.242674</td>\n",
       "      <td>0.019615</td>\n",
       "      <td>0.260638</td>\n",
       "      <td>0.141741</td>\n",
       "      <td>0.012120</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>0.033094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.206959</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.684147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.423187</td>\n",
       "      <td>0.321434</td>\n",
       "      <td>0.221016</td>\n",
       "      <td>0.326620</td>\n",
       "      <td>0.243296</td>\n",
       "      <td>0.169183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205537</td>\n",
       "      <td>0.074396</td>\n",
       "      <td>0.022891</td>\n",
       "      <td>0.175307</td>\n",
       "      <td>0.075826</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.045449</td>\n",
       "      <td>0.178734</td>\n",
       "      <td>0.058090</td>\n",
       "      <td>0.048156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.267749</td>\n",
       "      <td>0.222755</td>\n",
       "      <td>0.515099</td>\n",
       "      <td>0.423187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225265</td>\n",
       "      <td>0.024054</td>\n",
       "      <td>0.221619</td>\n",
       "      <td>0.124094</td>\n",
       "      <td>0.067933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049686</td>\n",
       "      <td>0.218340</td>\n",
       "      <td>0.337795</td>\n",
       "      <td>0.068941</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>0.143202</td>\n",
       "      <td>0.130254</td>\n",
       "      <td>0.075702</td>\n",
       "      <td>0.237466</td>\n",
       "      <td>0.110672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>0.191546</td>\n",
       "      <td>0.133421</td>\n",
       "      <td>0.260638</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.143202</td>\n",
       "      <td>0.227571</td>\n",
       "      <td>0.025672</td>\n",
       "      <td>0.209403</td>\n",
       "      <td>0.095522</td>\n",
       "      <td>0.235482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178394</td>\n",
       "      <td>0.222179</td>\n",
       "      <td>0.336911</td>\n",
       "      <td>0.308112</td>\n",
       "      <td>0.126345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.198749</td>\n",
       "      <td>0.242173</td>\n",
       "      <td>0.422373</td>\n",
       "      <td>0.182413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>0.044175</td>\n",
       "      <td>0.157720</td>\n",
       "      <td>0.141741</td>\n",
       "      <td>0.045449</td>\n",
       "      <td>0.130254</td>\n",
       "      <td>0.261334</td>\n",
       "      <td>0.049302</td>\n",
       "      <td>0.031380</td>\n",
       "      <td>0.216983</td>\n",
       "      <td>0.025018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014361</td>\n",
       "      <td>0.233683</td>\n",
       "      <td>0.066077</td>\n",
       "      <td>0.263634</td>\n",
       "      <td>0.142017</td>\n",
       "      <td>0.198749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.310756</td>\n",
       "      <td>0.574969</td>\n",
       "      <td>0.171765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.031991</td>\n",
       "      <td>0.271320</td>\n",
       "      <td>0.012120</td>\n",
       "      <td>0.178734</td>\n",
       "      <td>0.075702</td>\n",
       "      <td>0.072916</td>\n",
       "      <td>0.134682</td>\n",
       "      <td>0.118834</td>\n",
       "      <td>0.142704</td>\n",
       "      <td>0.248029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254972</td>\n",
       "      <td>0.113076</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.274958</td>\n",
       "      <td>0.018482</td>\n",
       "      <td>0.242173</td>\n",
       "      <td>0.310756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100227</td>\n",
       "      <td>0.180631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>0.075524</td>\n",
       "      <td>0.135513</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>0.058090</td>\n",
       "      <td>0.237466</td>\n",
       "      <td>0.206501</td>\n",
       "      <td>0.084420</td>\n",
       "      <td>0.196309</td>\n",
       "      <td>0.141085</td>\n",
       "      <td>0.230036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083791</td>\n",
       "      <td>0.452231</td>\n",
       "      <td>0.188752</td>\n",
       "      <td>0.270047</td>\n",
       "      <td>0.192889</td>\n",
       "      <td>0.422373</td>\n",
       "      <td>0.574969</td>\n",
       "      <td>0.100227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.273330</td>\n",
       "      <td>0.033094</td>\n",
       "      <td>0.048156</td>\n",
       "      <td>0.110672</td>\n",
       "      <td>0.076221</td>\n",
       "      <td>0.154555</td>\n",
       "      <td>0.137052</td>\n",
       "      <td>0.052047</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>0.194761</td>\n",
       "      <td>0.167391</td>\n",
       "      <td>0.106140</td>\n",
       "      <td>0.319305</td>\n",
       "      <td>0.182413</td>\n",
       "      <td>0.171765</td>\n",
       "      <td>0.180631</td>\n",
       "      <td>0.134994</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129 rows Ã— 1129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     1.000000  0.231838  0.105004  0.206959  0.267749  0.631039  0.194382   \n",
       "1     0.231838  1.000000  0.290545  0.025862  0.222755  0.163703  0.122384   \n",
       "2     0.105004  0.290545  1.000000  0.684147  0.515099  0.118176  0.234398   \n",
       "3     0.206959  0.025862  0.684147  1.000000  0.423187  0.321434  0.221016   \n",
       "4     0.267749  0.222755  0.515099  0.423187  1.000000  0.225265  0.024054   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1124  0.191546  0.133421  0.260638  0.006107  0.143202  0.227571  0.025672   \n",
       "1125  0.044175  0.157720  0.141741  0.045449  0.130254  0.261334  0.049302   \n",
       "1126  0.031991  0.271320  0.012120  0.178734  0.075702  0.072916  0.134682   \n",
       "1127  0.075524  0.135513  0.005646  0.058090  0.237466  0.206501  0.084420   \n",
       "1128  0.011537  0.273330  0.033094  0.048156  0.110672  0.076221  0.154555   \n",
       "\n",
       "          7         8         9     ...      1119      1120      1121  \\\n",
       "0     0.480949  0.642868  0.043913  ...  0.142265  0.118421  0.036892   \n",
       "1     0.238191  0.320355  0.171362  ...  0.164165  0.108097  0.010622   \n",
       "2     0.063864  0.027732  0.428390  ...  0.212825  0.147968  0.065598   \n",
       "3     0.326620  0.243296  0.169183  ...  0.205537  0.074396  0.022891   \n",
       "4     0.221619  0.124094  0.067933  ...  0.049686  0.218340  0.337795   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1124  0.209403  0.095522  0.235482  ...  0.178394  0.222179  0.336911   \n",
       "1125  0.031380  0.216983  0.025018  ...  0.014361  0.233683  0.066077   \n",
       "1126  0.118834  0.142704  0.248029  ...  0.254972  0.113076  0.009578   \n",
       "1127  0.196309  0.141085  0.230036  ...  0.083791  0.452231  0.188752   \n",
       "1128  0.137052  0.052047  0.005919  ...  0.024717  0.194761  0.167391   \n",
       "\n",
       "          1122      1123      1124      1125      1126      1127      1128  \n",
       "0     0.009484  0.172658  0.191546  0.044175  0.031991  0.075524  0.011537  \n",
       "1     0.001557  0.024834  0.133421  0.157720  0.271320  0.135513  0.273330  \n",
       "2     0.242674  0.019615  0.260638  0.141741  0.012120  0.005646  0.033094  \n",
       "3     0.175307  0.075826  0.006107  0.045449  0.178734  0.058090  0.048156  \n",
       "4     0.068941  0.014292  0.143202  0.130254  0.075702  0.237466  0.110672  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1124  0.308112  0.126345  1.000000  0.198749  0.242173  0.422373  0.182413  \n",
       "1125  0.263634  0.142017  0.198749  1.000000  0.310756  0.574969  0.171765  \n",
       "1126  0.274958  0.018482  0.242173  0.310756  1.000000  0.100227  0.180631  \n",
       "1127  0.270047  0.192889  0.422373  0.574969  0.100227  1.000000  0.134994  \n",
       "1128  0.106140  0.319305  0.182413  0.171765  0.180631  0.134994  1.000000  \n",
       "\n",
       "[1129 rows x 1129 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.columns = list(features) + [\"outputs\"]\n",
    "corrs = data.corr().abs()\n",
    "importances = corrs.values[-1][:-1]\n",
    "\n",
    "top_columns = np.argpartition(importances, -num_features)[-num_features:]\n",
    "corrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(corrs.values[-1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_top_cols = heapq.nlargest(150, range(len(importances)), importances.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_top_cols.sort()\n",
    "top_columns.sort()\n",
    "# test_top_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).iloc[:,top_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for early-fusion approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/compiled_dataset_RSbivariate_without_controls_v7.xlsx\", header = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = df[(\"behavioral\", \"wab_aq_bd\")].values\n",
    "outputs = outputs.reshape(len(outputs), 1)\n",
    "\n",
    "data = {}\n",
    "\n",
    "data[\"AQ\"] = df[(\"behavioral\", \"wab_aq_bd\")].values[:, np.newaxis]\n",
    "data[\"DM\"] = df[\"demographic_info\"].values \n",
    "\n",
    "\n",
    "featuresFAL = [\"fa_avg_ccmaj\", \"fa_avg_ccmin\", \"fa_avg_lifof\", \"fa_avg_lilf\", \"fa_avg_lslf\", \"fa_avg_lunc\", \"fa_avg_larc\"]\n",
    "featuresFAR = [\"fa_avg_rifof\", \"fa_avg_rilf\", \"fa_avg_rslf\", \"fa_avg_runc\", \"fa_avg_rarc\"]\n",
    "FA_L = df[\"average_FA_values\"][featuresFAL].fillna(0).values\n",
    "FA_R = df[\"average_FA_values\"][featuresFAR].fillna(df[\"average_FA_values\"][featuresFAR].mean()).values\n",
    "data[\"FA\"] = np.hstack((FA_L, FA_R))\n",
    "\n",
    "data[\"PS_G\"] = df[\"percent_spared_in_gray_matter\"].values\n",
    "data[\"PS_W\"] = df[\"percent_spared_in_white_matter\"].values\n",
    "\n",
    "data[\"RS\"] = df[\"restingstate_bivariate_correlations\"].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AQ'],\n",
       " ['DM'],\n",
       " ['FA'],\n",
       " ['PS_G'],\n",
       " ['PS_W'],\n",
       " ['RS'],\n",
       " ['LS'],\n",
       " ['BH'],\n",
       " ['AQ', 'DM'],\n",
       " ['AQ', 'FA'],\n",
       " ['AQ', 'PS_G'],\n",
       " ['AQ', 'PS_W'],\n",
       " ['AQ', 'RS'],\n",
       " ['AQ', 'LS'],\n",
       " ['AQ', 'BH'],\n",
       " ['DM', 'FA'],\n",
       " ['DM', 'PS_G'],\n",
       " ['DM', 'PS_W'],\n",
       " ['DM', 'RS'],\n",
       " ['DM', 'LS'],\n",
       " ['DM', 'BH'],\n",
       " ['FA', 'PS_G'],\n",
       " ['FA', 'PS_W'],\n",
       " ['FA', 'RS'],\n",
       " ['FA', 'LS'],\n",
       " ['FA', 'BH'],\n",
       " ['PS_G', 'PS_W'],\n",
       " ['PS_G', 'RS'],\n",
       " ['PS_G', 'LS'],\n",
       " ['PS_G', 'BH'],\n",
       " ['PS_W', 'RS'],\n",
       " ['PS_W', 'LS'],\n",
       " ['PS_W', 'BH'],\n",
       " ['RS', 'LS'],\n",
       " ['RS', 'BH'],\n",
       " ['LS', 'BH'],\n",
       " ['AQ', 'DM', 'FA'],\n",
       " ['AQ', 'DM', 'PS_G'],\n",
       " ['AQ', 'DM', 'PS_W'],\n",
       " ['AQ', 'DM', 'RS'],\n",
       " ['AQ', 'DM', 'LS'],\n",
       " ['AQ', 'DM', 'BH'],\n",
       " ['AQ', 'FA', 'PS_G'],\n",
       " ['AQ', 'FA', 'PS_W'],\n",
       " ['AQ', 'FA', 'RS'],\n",
       " ['AQ', 'FA', 'LS'],\n",
       " ['AQ', 'FA', 'BH'],\n",
       " ['AQ', 'PS_G', 'PS_W'],\n",
       " ['AQ', 'PS_G', 'RS'],\n",
       " ['AQ', 'PS_G', 'LS'],\n",
       " ['AQ', 'PS_G', 'BH'],\n",
       " ['AQ', 'PS_W', 'RS'],\n",
       " ['AQ', 'PS_W', 'LS'],\n",
       " ['AQ', 'PS_W', 'BH'],\n",
       " ['AQ', 'RS', 'LS'],\n",
       " ['AQ', 'RS', 'BH'],\n",
       " ['AQ', 'LS', 'BH'],\n",
       " ['DM', 'FA', 'PS_G'],\n",
       " ['DM', 'FA', 'PS_W'],\n",
       " ['DM', 'FA', 'RS'],\n",
       " ['DM', 'FA', 'LS'],\n",
       " ['DM', 'FA', 'BH'],\n",
       " ['DM', 'PS_G', 'PS_W'],\n",
       " ['DM', 'PS_G', 'RS'],\n",
       " ['DM', 'PS_G', 'LS'],\n",
       " ['DM', 'PS_G', 'BH'],\n",
       " ['DM', 'PS_W', 'RS'],\n",
       " ['DM', 'PS_W', 'LS'],\n",
       " ['DM', 'PS_W', 'BH'],\n",
       " ['DM', 'RS', 'LS'],\n",
       " ['DM', 'RS', 'BH'],\n",
       " ['DM', 'LS', 'BH'],\n",
       " ['FA', 'PS_G', 'PS_W'],\n",
       " ['FA', 'PS_G', 'RS'],\n",
       " ['FA', 'PS_G', 'LS'],\n",
       " ['FA', 'PS_G', 'BH'],\n",
       " ['FA', 'PS_W', 'RS'],\n",
       " ['FA', 'PS_W', 'LS'],\n",
       " ['FA', 'PS_W', 'BH'],\n",
       " ['FA', 'RS', 'LS'],\n",
       " ['FA', 'RS', 'BH'],\n",
       " ['FA', 'LS', 'BH'],\n",
       " ['PS_G', 'PS_W', 'RS'],\n",
       " ['PS_G', 'PS_W', 'LS'],\n",
       " ['PS_G', 'PS_W', 'BH'],\n",
       " ['PS_G', 'RS', 'LS'],\n",
       " ['PS_G', 'RS', 'BH'],\n",
       " ['PS_G', 'LS', 'BH'],\n",
       " ['PS_W', 'RS', 'LS'],\n",
       " ['PS_W', 'RS', 'BH'],\n",
       " ['PS_W', 'LS', 'BH'],\n",
       " ['RS', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G'],\n",
       " ['AQ', 'DM', 'FA', 'PS_W'],\n",
       " ['AQ', 'DM', 'FA', 'RS'],\n",
       " ['AQ', 'DM', 'FA', 'LS'],\n",
       " ['AQ', 'DM', 'FA', 'BH'],\n",
       " ['AQ', 'DM', 'PS_G', 'PS_W'],\n",
       " ['AQ', 'DM', 'PS_G', 'RS'],\n",
       " ['AQ', 'DM', 'PS_G', 'LS'],\n",
       " ['AQ', 'DM', 'PS_G', 'BH'],\n",
       " ['AQ', 'DM', 'PS_W', 'RS'],\n",
       " ['AQ', 'DM', 'PS_W', 'LS'],\n",
       " ['AQ', 'DM', 'PS_W', 'BH'],\n",
       " ['AQ', 'DM', 'RS', 'LS'],\n",
       " ['AQ', 'DM', 'RS', 'BH'],\n",
       " ['AQ', 'DM', 'LS', 'BH'],\n",
       " ['AQ', 'FA', 'PS_G', 'PS_W'],\n",
       " ['AQ', 'FA', 'PS_G', 'RS'],\n",
       " ['AQ', 'FA', 'PS_G', 'LS'],\n",
       " ['AQ', 'FA', 'PS_G', 'BH'],\n",
       " ['AQ', 'FA', 'PS_W', 'RS'],\n",
       " ['AQ', 'FA', 'PS_W', 'LS'],\n",
       " ['AQ', 'FA', 'PS_W', 'BH'],\n",
       " ['AQ', 'FA', 'RS', 'LS'],\n",
       " ['AQ', 'FA', 'RS', 'BH'],\n",
       " ['AQ', 'FA', 'LS', 'BH'],\n",
       " ['AQ', 'PS_G', 'PS_W', 'RS'],\n",
       " ['AQ', 'PS_G', 'PS_W', 'LS'],\n",
       " ['AQ', 'PS_G', 'PS_W', 'BH'],\n",
       " ['AQ', 'PS_G', 'RS', 'LS'],\n",
       " ['AQ', 'PS_G', 'RS', 'BH'],\n",
       " ['AQ', 'PS_G', 'LS', 'BH'],\n",
       " ['AQ', 'PS_W', 'RS', 'LS'],\n",
       " ['AQ', 'PS_W', 'RS', 'BH'],\n",
       " ['AQ', 'PS_W', 'LS', 'BH'],\n",
       " ['AQ', 'RS', 'LS', 'BH'],\n",
       " ['DM', 'FA', 'PS_G', 'PS_W'],\n",
       " ['DM', 'FA', 'PS_G', 'RS'],\n",
       " ['DM', 'FA', 'PS_G', 'LS'],\n",
       " ['DM', 'FA', 'PS_G', 'BH'],\n",
       " ['DM', 'FA', 'PS_W', 'RS'],\n",
       " ['DM', 'FA', 'PS_W', 'LS'],\n",
       " ['DM', 'FA', 'PS_W', 'BH'],\n",
       " ['DM', 'FA', 'RS', 'LS'],\n",
       " ['DM', 'FA', 'RS', 'BH'],\n",
       " ['DM', 'FA', 'LS', 'BH'],\n",
       " ['DM', 'PS_G', 'PS_W', 'RS'],\n",
       " ['DM', 'PS_G', 'PS_W', 'LS'],\n",
       " ['DM', 'PS_G', 'PS_W', 'BH'],\n",
       " ['DM', 'PS_G', 'RS', 'LS'],\n",
       " ['DM', 'PS_G', 'RS', 'BH'],\n",
       " ['DM', 'PS_G', 'LS', 'BH'],\n",
       " ['DM', 'PS_W', 'RS', 'LS'],\n",
       " ['DM', 'PS_W', 'RS', 'BH'],\n",
       " ['DM', 'PS_W', 'LS', 'BH'],\n",
       " ['DM', 'RS', 'LS', 'BH'],\n",
       " ['FA', 'PS_G', 'PS_W', 'RS'],\n",
       " ['FA', 'PS_G', 'PS_W', 'LS'],\n",
       " ['FA', 'PS_G', 'PS_W', 'BH'],\n",
       " ['FA', 'PS_G', 'RS', 'LS'],\n",
       " ['FA', 'PS_G', 'RS', 'BH'],\n",
       " ['FA', 'PS_G', 'LS', 'BH'],\n",
       " ['FA', 'PS_W', 'RS', 'LS'],\n",
       " ['FA', 'PS_W', 'RS', 'BH'],\n",
       " ['FA', 'PS_W', 'LS', 'BH'],\n",
       " ['FA', 'RS', 'LS', 'BH'],\n",
       " ['PS_G', 'PS_W', 'RS', 'LS'],\n",
       " ['PS_G', 'PS_W', 'RS', 'BH'],\n",
       " ['PS_G', 'PS_W', 'LS', 'BH'],\n",
       " ['PS_G', 'RS', 'LS', 'BH'],\n",
       " ['PS_W', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'PS_W'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'RS'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'LS'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_W', 'RS'],\n",
       " ['AQ', 'DM', 'FA', 'PS_W', 'LS'],\n",
       " ['AQ', 'DM', 'FA', 'PS_W', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'RS', 'LS'],\n",
       " ['AQ', 'DM', 'FA', 'RS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'PS_G', 'PS_W', 'RS'],\n",
       " ['AQ', 'DM', 'PS_G', 'PS_W', 'LS'],\n",
       " ['AQ', 'DM', 'PS_G', 'PS_W', 'BH'],\n",
       " ['AQ', 'DM', 'PS_G', 'RS', 'LS'],\n",
       " ['AQ', 'DM', 'PS_G', 'RS', 'BH'],\n",
       " ['AQ', 'DM', 'PS_G', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'PS_W', 'RS', 'LS'],\n",
       " ['AQ', 'DM', 'PS_W', 'RS', 'BH'],\n",
       " ['AQ', 'DM', 'PS_W', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'FA', 'PS_G', 'PS_W', 'RS'],\n",
       " ['AQ', 'FA', 'PS_G', 'PS_W', 'LS'],\n",
       " ['AQ', 'FA', 'PS_G', 'PS_W', 'BH'],\n",
       " ['AQ', 'FA', 'PS_G', 'RS', 'LS'],\n",
       " ['AQ', 'FA', 'PS_G', 'RS', 'BH'],\n",
       " ['AQ', 'FA', 'PS_G', 'LS', 'BH'],\n",
       " ['AQ', 'FA', 'PS_W', 'RS', 'LS'],\n",
       " ['AQ', 'FA', 'PS_W', 'RS', 'BH'],\n",
       " ['AQ', 'FA', 'PS_W', 'LS', 'BH'],\n",
       " ['AQ', 'FA', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'PS_G', 'PS_W', 'RS', 'LS'],\n",
       " ['AQ', 'PS_G', 'PS_W', 'RS', 'BH'],\n",
       " ['AQ', 'PS_G', 'PS_W', 'LS', 'BH'],\n",
       " ['AQ', 'PS_G', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['DM', 'FA', 'PS_G', 'PS_W', 'RS'],\n",
       " ['DM', 'FA', 'PS_G', 'PS_W', 'LS'],\n",
       " ['DM', 'FA', 'PS_G', 'PS_W', 'BH'],\n",
       " ['DM', 'FA', 'PS_G', 'RS', 'LS'],\n",
       " ['DM', 'FA', 'PS_G', 'RS', 'BH'],\n",
       " ['DM', 'FA', 'PS_G', 'LS', 'BH'],\n",
       " ['DM', 'FA', 'PS_W', 'RS', 'LS'],\n",
       " ['DM', 'FA', 'PS_W', 'RS', 'BH'],\n",
       " ['DM', 'FA', 'PS_W', 'LS', 'BH'],\n",
       " ['DM', 'FA', 'RS', 'LS', 'BH'],\n",
       " ['DM', 'PS_G', 'PS_W', 'RS', 'LS'],\n",
       " ['DM', 'PS_G', 'PS_W', 'RS', 'BH'],\n",
       " ['DM', 'PS_G', 'PS_W', 'LS', 'BH'],\n",
       " ['DM', 'PS_G', 'RS', 'LS', 'BH'],\n",
       " ['DM', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['FA', 'PS_G', 'PS_W', 'RS', 'LS'],\n",
       " ['FA', 'PS_G', 'PS_W', 'RS', 'BH'],\n",
       " ['FA', 'PS_G', 'PS_W', 'LS', 'BH'],\n",
       " ['FA', 'PS_G', 'RS', 'LS', 'BH'],\n",
       " ['FA', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['PS_G', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'PS_W', 'RS'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'PS_W', 'LS'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'PS_W', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'RS', 'LS'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'RS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_W', 'RS', 'LS'],\n",
       " ['AQ', 'DM', 'FA', 'PS_W', 'RS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_W', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'PS_G', 'PS_W', 'RS', 'LS'],\n",
       " ['AQ', 'DM', 'PS_G', 'PS_W', 'RS', 'BH'],\n",
       " ['AQ', 'DM', 'PS_G', 'PS_W', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'PS_G', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'FA', 'PS_G', 'PS_W', 'RS', 'LS'],\n",
       " ['AQ', 'FA', 'PS_G', 'PS_W', 'RS', 'BH'],\n",
       " ['AQ', 'FA', 'PS_G', 'PS_W', 'LS', 'BH'],\n",
       " ['AQ', 'FA', 'PS_G', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'FA', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'PS_G', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['DM', 'FA', 'PS_G', 'PS_W', 'RS', 'LS'],\n",
       " ['DM', 'FA', 'PS_G', 'PS_W', 'RS', 'BH'],\n",
       " ['DM', 'FA', 'PS_G', 'PS_W', 'LS', 'BH'],\n",
       " ['DM', 'FA', 'PS_G', 'RS', 'LS', 'BH'],\n",
       " ['DM', 'FA', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['DM', 'PS_G', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['FA', 'PS_G', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'PS_W', 'RS', 'LS'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'PS_W', 'RS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'PS_W', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'PS_G', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'FA', 'PS_G', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['DM', 'FA', 'PS_G', 'PS_W', 'RS', 'LS', 'BH'],\n",
       " ['AQ', 'DM', 'FA', 'PS_G', 'PS_W', 'RS', 'LS', 'BH']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "all_features = [\"AQ\", \"DM\", \"FA\", \"PS_G\", \"PS_W\", \"RS\", \"LS\", \"BH\"]\n",
    "all_combinations = []\n",
    "for i in range(1,len(all_features)+1):\n",
    "    temp = list( map(list, list(itertools.combinations(all_features, i))))\n",
    "    all_combinations += temp \n",
    "\n",
    "# for i in range(len(all_combinations)):\n",
    "#     all_combinations[i] = \"-\".join(all_combinations[i])\n",
    "    \n",
    "# len(all_combinations)\n",
    "# all_combinations.append(\"stan_optimal\")\n",
    "\n",
    "all_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries import *\n",
    "\n",
    "df = pd.read_excel(\"../data/compiled_dataset_RSbivariate_without_controls_v7.xlsx\", header = [0,1])\n",
    "outputs = df[(\"behavioral\", \"wab_aq_bd\")].values\n",
    "outputs = outputs.reshape(len(outputs),1)\n",
    "\n",
    "data = {}\n",
    "\n",
    "# AQ - Aphasia Quotient\n",
    "data[\"AQ\"] = pd.DataFrame(df[('behavioral', \"wab_aq_bd\")].values, columns = [\"wab_aq_bd\"]) \n",
    "\n",
    "# DM - Demographics\n",
    "data[\"DM\"] = df[\"demographic_info\"]\n",
    "\n",
    "# FA - Fractional Anisotropy\n",
    "featuresFAL = [\"fa_avg_ccmaj\", \"fa_avg_ccmin\", \"fa_avg_lifof\", \"fa_avg_lilf\", \"fa_avg_lslf\", \"fa_avg_lunc\", \"fa_avg_larc\"]\n",
    "featuresFAR = [\"fa_avg_rifof\", \"fa_avg_rilf\", \"fa_avg_rslf\", \"fa_avg_runc\", \"fa_avg_rarc\"]\n",
    "FA_L = df[\"average_FA_values\"][featuresFAL].fillna(0).values\n",
    "FA_R = df[\"average_FA_values\"][featuresFAR].fillna(df[\"average_FA_values\"][featuresFAR].mean()).values\n",
    "data[\"FA\"] = pd.DataFrame(np.hstack((FA_L, FA_R)), columns = featuresFAL+featuresFAR)\n",
    "\n",
    "# PS_G - percent grey matter per region  \n",
    "data[\"PS_G\"] = df[\"percent_spared_in_gray_matter\"]\n",
    "\n",
    "# PS_W - percent white matter per region  \n",
    "data[\"PS_W\"] = df[\"percent_spared_in_white_matter\"]\n",
    "\n",
    "# RS - Resting state data\n",
    "data[\"RS\"] = df[\"restingstate_bivariate_correlations\"]\n",
    "\n",
    "# LS - Lesion size (Total)   ; Need to add lesion size per region\n",
    "data[\"LS\"] = pd.DataFrame(df[(\"lesion_size\", \"lesion_size_ls\")].values, columns = [\"lesion_size_ls\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 747)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getData(feature_combo):\n",
    "    features = feature_combo.split(\"-\")\n",
    "    \n",
    "    correlations = []\n",
    "    for i,dataset in enumerate(features):\n",
    "        if i==0:\n",
    "            correlations = data[dataset].values\n",
    "            featureList = list(data[dataset].columns)\n",
    "            \n",
    "        else:\n",
    "            correlations = np.hstack((correlations, data[dataset].values))\n",
    "            featureList += list(data[dataset].columns)\n",
    "    \n",
    "    return correlations, featureList\n",
    "\n",
    "# print(all_combinations[10])\n",
    "\n",
    "all_features = [\"AQ\", \"DM\", \"FA\", \"PS_G\", \"PS_W\", \"RS\", \"LS\"]\n",
    "corrdata, datafeatures = getData(\"AQ-DM-FA-PS_G-PS_W-RS-LS\")\n",
    "corrdata.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"DM\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DM_RS_stan'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"DM-RS-stan_optimal\".split(\"_\")[0]\n",
    "x = x.split(\"-\")\n",
    "\"_\".join(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p2/17j674213qv7q4cbzhk97jch0000gn/T/ipykernel_50319/411950099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "x = pd.DataFrame(np.ones([5,5]), columns=[\"A\", \"B\", \"C\", \"D\", \"E\"])\n",
    "y = np.ones([5,1])\n",
    "x = np.hstack((x, y))\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.546296\n",
       "1     0.000000\n",
       "2     0.305556\n",
       "3     0.500000\n",
       "4    -0.064815\n",
       "5     0.335648\n",
       "6     0.194444\n",
       "7     0.277778\n",
       "8     0.462963\n",
       "9     0.370370\n",
       "10    0.194444\n",
       "11    0.074074\n",
       "12    0.522487\n",
       "13    0.500000\n",
       "14    0.157407\n",
       "15    0.074074\n",
       "16    0.481481\n",
       "17    0.379630\n",
       "18    0.166667\n",
       "19    0.416667\n",
       "20    0.212963\n",
       "21    0.101852\n",
       "22    0.037037\n",
       "23    0.129630\n",
       "24    0.055556\n",
       "25    0.138889\n",
       "26    0.287037\n",
       "27    0.407407\n",
       "28    0.092593\n",
       "29    0.240741\n",
       "30    0.240000\n",
       "31    0.540000\n",
       "32    0.300000\n",
       "33    0.440000\n",
       "34    0.160000\n",
       "35    0.299851\n",
       "36    0.090000\n",
       "37    0.210000\n",
       "38    0.388540\n",
       "39    0.303958\n",
       "40    0.440000\n",
       "41    0.482366\n",
       "42    0.193497\n",
       "43    0.435933\n",
       "44    0.264000\n",
       "45    0.425919\n",
       "46    0.450000\n",
       "47    0.400000\n",
       "48    0.550000\n",
       "49    0.450000\n",
       "50    0.650000\n",
       "51    0.600000\n",
       "52    0.350000\n",
       "53    0.250000\n",
       "54    0.000000\n",
       "Name: (behavioral, difference_post_pre_bd), dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"../data/compiled_dataset_RSbivariate_without_controls_v7.xlsx\", header = [0,1])\n",
    "data[\"demographic_info\"].shape\n",
    "data[(\"behavioral\", \"difference_post_pre_bd\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
