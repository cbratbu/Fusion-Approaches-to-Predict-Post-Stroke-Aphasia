{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries import * \n",
    "from getData import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries import *\n",
    "from getData import *\n",
    "from models import *\n",
    "from params import *\n",
    "from utils import *\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, settings):\n",
    "        self.cv = settings[\"Cross Validation Type\"]\n",
    "        self.metric = settings[\"metric\"]\n",
    "        self.repeat_features = settings[\"repeat features\"]\n",
    "        self.m = settings[\"model\"]\n",
    "        self.verbose = settings[\"verbose\"]\n",
    "        if self.cv != \"kTkV\" and self.metric != \"all-metrics\":\n",
    "            print(\"original model = \", settings[\"model\"], \" ---- \")\n",
    "            self.model = self.get_model(settings[\"model\"])\n",
    "        self.pca = PCA(n_components=2)\n",
    "        self.stratified = settings[\"stratified\"]\n",
    "        # self.order = settings[\"order\"]\n",
    "        self.same_split = settings[\"same split\"]\n",
    "        self.num_features = settings[\"top_k\"]\n",
    "        \n",
    "        self.feature_reduction = settings[\"feature reduction\"]\n",
    "        self.FR_step = settings[\"features reduced per step\"]\n",
    "        \n",
    "        self.source = settings[\"data\"]\n",
    "        self.feature_f = open(\"features.txt\", \"w\")\n",
    "        self.init(settings)\n",
    "        # self.feature_f.close()\n",
    "\n",
    "    def reduce(self):\n",
    "        self.outputs = self.outputs.reshape(self.outputs.shape[0], 1)\n",
    "        self.data = np.hstack((self.data, self.outputs))\n",
    "        self.data = pd.DataFrame(self.data)\n",
    "\n",
    "        corrs = self.data.corr().abs()\n",
    "        importances = corrs.values[-1][:-1]\n",
    "\n",
    "        top_columns = np.argpartition(importances, -self.num_features)[-self.num_features:]\n",
    "\n",
    "        self.data = self.data.iloc[:,top_columns]\n",
    "        self.outputs = self.outputs.ravel()\n",
    "        self.data = self.data.values\n",
    "        \n",
    "\n",
    "    def init(self, augmentation_settings): # gets the data to train and test\n",
    "        \n",
    "        # class to get the data from 'getData.py'\n",
    "        GET = getData(augmentation_settings) \n",
    "        \n",
    "        self.all_features, self.data, self.outputs = GET.data()\n",
    "        self.all_features = pd.Index(self.all_features)\n",
    "        \n",
    "        print(\"data shape = \", self.data.shape)\n",
    "        print(\"outputs shape = \", self.outputs.shape)\n",
    "        self.outputs = self.outputs.ravel()\n",
    "    \n",
    "        self.forward()\n",
    "        # Check for stratified sampling part later \n",
    "        \n",
    "        # if self.stratified == True:\n",
    "        #     self.data = pd.DataFrame(self.data)\n",
    "        #     self.data[\"outputs\"] = self.outputs \n",
    "        #     # if self.order ==\"ascending\":\n",
    "        #     self.data = self.data.sort_values(by = \"outputs\", ascending = True)\n",
    "        #     # elif self.order == \"descending\":\n",
    "        #         # self.data = self.data.sort_values(by = \"outputs\", ascending = False)\n",
    "        #     self.outputs = self.data[\"outputs\"].values\n",
    "        #     self.data = self.data.drop([\"outputs\"], axis = 1)\n",
    "        #     self.data = self.data.values\n",
    "            \n",
    "        # self.forward()\n",
    "\n",
    "\n",
    "    def CV_(self):\n",
    "        if self.cv == \"LOO\":\n",
    "            return 55\n",
    "        elif self.cv == \"LFiveO\":\n",
    "            return 11\n",
    "        elif self.cv == \"5Fold\":\n",
    "            return 5\n",
    "        elif self.cv == \"kTkV\":\n",
    "            return 10\n",
    "\n",
    "    def correct_metric(self):\n",
    "        if self.metric == \"MSE\":\n",
    "            self.metric = \"neg_mean_squared_error\"\n",
    "        elif self.metric == \"MAE\":\n",
    "            self.metric = \"neg_mean_absolute_error\"\n",
    "            \n",
    "\n",
    "    def get_model(self, model, params=None):\n",
    "\n",
    "        m = getModel(model)\n",
    "        params = allParams(model) if params == None else params\n",
    "\n",
    "        if self.cv != \"kTkV\" and self.metric != \"all-metrics\":\n",
    "            self.correct_metric()\n",
    "            return GridSearchCV( m(), params, cv= self.CV_(), scoring = self.metric , return_train_score = True, verbose = self.verbose)\n",
    "        else:\n",
    "            params = dict(zip(self.param_keys, params))\n",
    "            return m(**params)\n",
    "            # return make_pipeline(\n",
    "            #                     StandardScaler(),\n",
    "            #                     m(**params))\n",
    "\n",
    "##################################################################################################################################################################\n",
    "# the following functions are not necessary as of now\n",
    "##################################################################################################################################################################\n",
    "    #\n",
    "    # def train(self, data, outputs):\n",
    "    #     self.model.fit(data, outputs)\n",
    "    #\n",
    "    # def predict(self, data):\n",
    "    #     return self.model.predict(data)\n",
    "    #\n",
    "    # def get_score(self,data,outputs, return_ = False): #gives out R2 scores\n",
    "    #     print(\"R2 fit score = \", self.model.score(data, outputs), \"\\n\" )\n",
    "    #     if return_:\n",
    "    #         return self.model.score(data, outputs)\n",
    "    #\n",
    "    # def CrossValResults(self):\n",
    "    #     print(self.model.cv_results_)\n",
    "    #     print('\\n')\n",
    "    #\n",
    "    # def modify_data(self, data):\n",
    "    #     self.pca.fit(data)\n",
    "    #     raise NotImplementedError()\n",
    "    #\n",
    "    # def get_data(self):\n",
    "    #     X_train, X_test, y_train, y_test = train_test_split( self.data, self.outputs, test_size=0.09, random_state=42)\n",
    "    #\n",
    "    #     if self.cv != \"kTkV\":\n",
    "    #         X_train, y_train = self.data, self.outputs\n",
    "    #\n",
    "    #     print(\"train data shape = \", X_train.shape)\n",
    "    #     print(\"train labels shape = \", y_train.shape, \"\\n\")\n",
    "    #\n",
    "    #     print(\"test data shape = \", X_test.shape)\n",
    "    #     print(\"test labels shape = \", y_test.shape, \"\\n\")\n",
    "    #\n",
    "    #     return X_train, X_test, y_train, y_test\n",
    "    #\n",
    "    # def oneMetric_cv(self):\n",
    "    #     X_train, X_test, y_train, y_test = self.get_data()\n",
    "    #     self.train(X_train, y_train)\n",
    "    #\n",
    "    #     print(\"training performance\")\n",
    "    #     self.get_score(X_train, y_train)\n",
    "    #     self.train_predictions_ = self.predict(X_train)\n",
    "    #     # self.test_predictions_ = self.predict(X_test)\n",
    "    #    \n",
    "##################################################################################################################################################################    \n",
    "\n",
    "\n",
    "\n",
    "    def important_columns(self, data, outputs): \n",
    "        \"\"\"This function finds the names of important features in the data, either based on two factors\n",
    "            - Pearson Correlation with WAB scores \n",
    "            - Recurrent Feature Elimination (RFE)\n",
    "\n",
    "        Args:\n",
    "            data (numpy array): Input data without output column\n",
    "            outputs (numpy array): 1D array of WAB scores / any other output\n",
    "\n",
    "        Returns:\n",
    "            numpy array : finds the column index numbers and returns it \n",
    "        \"\"\"\n",
    "        # print(self.feature_reduction)\n",
    "        self.feature_f.write(self.feature_reduction + \"\\n\")\n",
    "        \n",
    "        if self.feature_reduction == \"pearson\":\n",
    "\n",
    "            outputs = outputs.reshape(outputs.shape[0], 1)\n",
    "            data = np.hstack((data, outputs))\n",
    "            data = pd.DataFrame(data)\n",
    "    \n",
    "            corrs = data.corr().abs()\n",
    "            importances = corrs.values[-1][:-1]\n",
    "    \n",
    "            # top_columns = np.argpartition(importances, -self.num_features)[-self.num_features:]\n",
    "            top_columns = heapq.nlargest(150, range(len(importances)), importances.take)\n",
    "            # print(top_columns[:3])\n",
    "            return top_columns\n",
    "            \n",
    "        elif self.feature_reduction == \"RFE\":\n",
    "\n",
    "            self.rfe = RFE(self.model, n_features_to_select = self.num_features, step=1)#self.FR_step)\n",
    "            self.rfe = self.rfe.fit(data, outputs)\n",
    "            features = np.arange(data.shape[1])\n",
    "            features = features[self.rfe.ranking_==1]\n",
    "            return features\n",
    "\n",
    "    def reduce_data(self, data):\n",
    "        \"\"\"filter important columns from the input data\n",
    "\n",
    "        Args:\n",
    "            data (numpy array): Input data without output columns\n",
    "\n",
    "        Returns:\n",
    "            numpy array: Input data with selected top features\n",
    "        \"\"\"\n",
    "        \n",
    "        data = pd.DataFrame(data)\n",
    "        # print(\"dataframe\")\n",
    "        data = data.iloc[:,self.top_columns]\n",
    "        # print(\"few columns\")\n",
    "        return data.values\n",
    "        \n",
    "        \n",
    "    def get_KFfname(self):\n",
    "        \"\"\"create a csv file name based on model parameter setting\n",
    "\n",
    "        Returns:\n",
    "            string: csv file name based on the model parameters \n",
    "        \"\"\"\n",
    "        \n",
    "        fname = \"\"\n",
    "        for i,param in enumerate(self.param_keys):\n",
    "            fname += \"[\" + param[0] + \"-\" + str(self.curr_param[i]) + \"]_\" \n",
    "        fname = fname[:-1] + \".csv\"\n",
    "        return fname\n",
    "        \n",
    "            \n",
    "    def get_folder_name(self, fname):\n",
    "        \"\"\"creates a folder with the training setting in the results folder\n",
    "\n",
    "        Args:\n",
    "            fname (string): csv file name to store model parameter-wise outputs\n",
    "\n",
    "        Returns:\n",
    "            string: folder_name + file_name to save model parameter-wise outputs. \n",
    "        \"\"\"\n",
    "        path = create_folder(self.source, fname)\n",
    "        stratified = \"\" if self.stratified!=True else \"stratified\"\n",
    "        fname = self.cv + \"_\" + self.m + \"_\" + self.metric + \"_top\" + str(self.num_features) + \"frs_\" + self.feature_reduction + \"_\"\n",
    "        return path + \"/\" + fname[:-1]\n",
    "    \n",
    "    \n",
    "    def features_init(self):\n",
    "        \"\"\"creates a folder to save outputs of important features\n",
    "\n",
    "            Initiate the csv writer to write the features in a file during cross validation\n",
    "\n",
    "        \"\"\"\n",
    "        folder = self.get_folder_name(\"features\")\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder,exist_ok=True)\n",
    "        file = self.get_KFfname()\n",
    "\n",
    "        self.writerfile = open( folder + \"/\" + file , 'w', newline='')\n",
    "        self.feature_writer = csv.writer(self.writerfile, delimiter=' ',  quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        \n",
    "    def save_features(self):\n",
    "        \"\"\"writes the important features to a csv file using the csv-writer\n",
    "        \n",
    "        \"\"\"\n",
    "        features = self.all_features[self.top_columns]\n",
    "        self.feature_writer.writerow(list(features.values))\n",
    "        \n",
    "    \n",
    "    def feature_close(self):\n",
    "        \"\"\"Closes the csv-writer to complete writing important features to a file\n",
    "        \"\"\"\n",
    "        self.writerfile.close()\n",
    "        \n",
    "\n",
    "    def validate(self, data, outputs, kf2 = None):\n",
    "        \"\"\"Does Cross valiation for kTkV training setting, Training for other settings\n",
    "\n",
    "        Args:\n",
    "            data (numpy array): input data\n",
    "            outputs (numpy array): WAB scores / output values\n",
    "            kf2 (cross validation setting, optional): kFold CV object as input. If not given, creates 10-Fold CV. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            float, float, float, float, object: train MSE mean, Validate MSE mean, train MAE mean, validate MAE mean, Best validate model\n",
    "        \"\"\"\n",
    "\n",
    "        ##################################################################################################################################################################\n",
    "        # Do not disturb the following few lines on k-fold setting\n",
    "        if kf2 != None: \n",
    "            if self.stratified:\n",
    "                class_labels = self.get_class_labels(splits = 5, outputs = outputs)\n",
    "            else:\n",
    "                class_labels = outputs\n",
    "        else:\n",
    "            if self.stratified != True: \n",
    "                if self.cv != \"LOO\":\n",
    "                    kf2 = KFold(n_splits=self.CV_(), shuffle = True)\n",
    "                    class_labels = outputs\n",
    "            else:\n",
    "                \n",
    "                kf2 = StratifiedKFold(n_splits=self.CV_(), shuffle = True)\n",
    "                class_labels = self.get_class_labels(splits = 5, outputs = outputs)\n",
    "\n",
    "            if self.cv == \"LOO\":\n",
    "                kf2 = KFold(n_splits=self.CV_(), shuffle=True)\n",
    "                class_labels = outputs\n",
    "                \n",
    "        ##################################################################################################################################################################\n",
    "        train_performance = []\n",
    "        train_performance_MAE = []\n",
    "\n",
    "        validate_performance = []\n",
    "        validate_performance_MAE = []\n",
    "\n",
    "        models = []\n",
    "\n",
    "        mean_train_MSE = []\n",
    "        mean_validate_MSE = []\n",
    "        mean_test_MSE = []\n",
    "        \n",
    "        cumulative_validate_predictions = []\n",
    "        cumulative_ground_truths = []\n",
    "\n",
    "        maxLoss = 1000 # some arbitrary max loss value for RMSE\n",
    "        self.best_features = None #to keep track of best features\n",
    "\n",
    "        for train_index, validate_index in kf2.split(data, class_labels):\n",
    "\n",
    "            # Model definition\n",
    "            self.model = self.get_model(self.m, self.curr_param) # gets the model initialization of \"m\" type and \"curr_param\" parameters\n",
    "            \n",
    "            X_train, X_validate = data[train_index], data[validate_index]\n",
    "            y_train, y_validate = outputs[train_index], outputs[validate_index]\n",
    "            # print(\"got val data\")\n",
    "            \n",
    "            if self.num_features!=-1: #(self.num_features!=-1 and self.cv!=\"kTkV\"):\n",
    "                self.top_columns = self.important_columns(X_train,y_train)\n",
    "                # print(\"found important columns\")\n",
    "                X_train = self.reduce_data(X_train)\n",
    "                # print(\"reduced train data\")\n",
    "                X_validate = self.reduce_data(X_validate)\n",
    "\n",
    "            # print(\"split val data\")\n",
    "            # print(\"important columns = \", self.top_columns)\n",
    "            self.save_features()\n",
    "\n",
    "            self.model.fit(X_train, y_train)            \n",
    "            train_predictions = self.model.predict(X_train)\n",
    "            # print(\"validate shape = \", X_validate.shape)\n",
    "            validate_predictions = self.model.predict(X_validate)\n",
    "            # return\n",
    "            # print(\"got val preds\")\n",
    "            \n",
    "            if self.cv != \"kTkV\":\n",
    "                cumulative_validate_predictions.append(validate_predictions)\n",
    "                cumulative_ground_truths.append(y_validate)\n",
    "                \n",
    "            models.append(self.model)\n",
    "\n",
    "            if mean_squared_error(validate_predictions,y_validate,squared=False) < maxLoss:\n",
    "                maxLoss = mean_squared_error(validate_predictions,y_validate,squared=False)\n",
    "                self.best_features = self.top_columns \n",
    " \n",
    "            # trainloss = mean_squared_error(train_predictions, y_train, squared=False)\n",
    "            valloss = mean_squared_error(validate_predictions,y_validate,squared=False)\n",
    "            self.feature_f.write(str(self.top_columns[:3]) + \" -- \"+ str(valloss) +\"\\n\")\n",
    "               \n",
    "            train_performance.append(mean_squared_error(train_predictions, y_train, squared=False))\n",
    "            validate_performance.append(mean_squared_error(validate_predictions,y_validate,squared=False))\n",
    "\n",
    "            train_performance_MAE.append(mean_absolute_error(train_predictions, y_train))\n",
    "            validate_performance_MAE.append(mean_absolute_error(validate_predictions,y_validate))\n",
    "\n",
    "        if self.cv != \"kTkV\":\n",
    "            self.save_file(cumulative_validate_predictions, cumulative_ground_truths)\n",
    "\n",
    "        model = models[np.argmin(validate_performance)]\n",
    "        self.top_columns = self.best_features\n",
    "        return np.mean(train_performance), np.mean(validate_performance), np.mean(train_performance_MAE), np.mean(validate_performance_MAE), model\n",
    "\n",
    "\n",
    "    def save_file(self, cumulative_validate_predictions, cumulative_ground_truths):\n",
    "        \"\"\"saves the predictions and ground truth values for each model setting for each training setting.\n",
    "\n",
    "        Args:\n",
    "            cumulative_validate_predictions (list[float]): list of predictions for each patient\n",
    "            cumulative_ground_truths (list[float]): list of ground truth scores for each patient\n",
    "        \"\"\"\n",
    "        \n",
    "        cumulative_validate_predictions = list(itertools.chain(*cumulative_validate_predictions))\n",
    "        cumulative_ground_truths = list(itertools.chain(*cumulative_ground_truths))\n",
    "        \n",
    "        predictions = {\n",
    "            \"predictions\" : cumulative_validate_predictions,\n",
    "            \"ground truth score\": cumulative_ground_truths,\n",
    "        }\n",
    "        folder_name = self.get_folder_name(\"outputs\")\n",
    "        \n",
    "        if not os.path.exists(folder_name ):\n",
    "            os.makedirs(folder_name,exist_ok=True)\n",
    "        \n",
    "        predictions = pd.DataFrame(predictions)\n",
    "        self.kFfname = self.get_KFfname()\n",
    "\n",
    "        predictions.to_csv(folder_name + \"/\" + self.kFfname)   \n",
    "        \n",
    "\n",
    "\n",
    "    def get_class_labels(self, splits, outputs):\n",
    "        \"\"\"Helper function. Used in stratifold setting. Not important for regular setting. \n",
    "\n",
    "        Args:\n",
    "            splits (int): number of buckets in training data during k-Fold CV\n",
    "            outputs (array[float]): WAB scores of each patient. \n",
    "\n",
    "        Returns:\n",
    "            array[float]: labels of each training example before splitting the data.\n",
    "        \"\"\"\n",
    "        x = np.ones(len(outputs))\n",
    "        \n",
    "        counter = 0\n",
    "        counter_update = int(len(outputs)/splits)\n",
    "        adder = 0\n",
    "        \n",
    "        while(counter < len(outputs)):\n",
    "            x[counter:counter + counter_update] += adder \n",
    "            adder += 1\n",
    "            counter += counter_update \n",
    "            \n",
    "        return x \n",
    "            \n",
    "\n",
    "    def train_kTkV(self):\n",
    "        \"\"\"Training loop for kTkV setting. Initiates Training set and Testing set here. Sends training data to validate function.\n",
    "\n",
    "        Returns:\n",
    "            float, float, float, float, float, float, object: trainMSE, testMSE, valMSE, trainMAE, valMAE, testMAE, best test model.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.stratified!=True:\n",
    "            kf = KFold(n_splits=11, shuffle = False)\n",
    "            class_labels = self.outputs\n",
    "        else:\n",
    "            kf = StratifiedKFold(n_splits=11, shuffle = False)\n",
    "            class_labels = self.get_class_labels(splits=5, outputs = self.outputs)\n",
    "\n",
    "        \n",
    "        train_performances = []\n",
    "        train_performances_MAE = []\n",
    "\n",
    "        validate_performances = []\n",
    "        validate_performances_MAE = []\n",
    "\n",
    "        test_performances = []\n",
    "        test_performances_MAE = []\n",
    "        \n",
    "        cumulative_test_predictions = []\n",
    "        cumulative_test_truths = []\n",
    "\n",
    "        models = []\n",
    "\n",
    "        for train_index, test_index in kf.split(self.data, class_labels):\n",
    "            X_train, X_test = self.data[train_index], self.data[test_index]\n",
    "            y_train, y_test = self.outputs[train_index], self.outputs[test_index]\n",
    "            # print('data split here')\n",
    "            train_performance, validate_performance, train_performance_MAE, validate_performance_MAE, model = self.validate(X_train, y_train)\n",
    "            # print(\"got performances\")\n",
    "            self.feature_f.write(str(self.top_columns[:3]) + \"\\n\")\n",
    "            X_train = self.reduce_data(X_train)\n",
    "            X_test = self.reduce_data(X_test)\n",
    "            # print(\"data reduced\")\n",
    "            models.append(model)\n",
    "\n",
    "            test_predictions = model.predict(X_test)\n",
    "            \n",
    "            cumulative_test_predictions.append(test_predictions)\n",
    "            cumulative_test_truths.append(y_test)\n",
    "\n",
    "            test_performance = mean_squared_error(test_predictions, y_test, squared=False)\n",
    "            test_performance_MAE = mean_absolute_error(test_predictions, y_test)\n",
    "\n",
    "            train_performances.append(train_performance)\n",
    "            train_performances_MAE.append(train_performance_MAE)\n",
    "\n",
    "            validate_performances.append(validate_performance)\n",
    "            validate_performances_MAE.append(validate_performance_MAE)\n",
    "\n",
    "            test_performances.append(test_performance)\n",
    "            test_performances_MAE.append(test_performance_MAE)\n",
    "        # print(\"loop ended\")\n",
    "        self.save_file(cumulative_test_predictions, cumulative_test_truths)\n",
    "        model = models[np.argmin(test_performances)]\n",
    "\n",
    "        return np.mean(train_performances), np.mean(validate_performances), np.mean(test_performances), np.mean(train_performances_MAE), np.mean(validate_performances_MAE), np.mean(test_performances_MAE), model\n",
    "\n",
    "\n",
    "    def get_params_(self):\n",
    "        \"\"\"returns the combination of different model parameters\n",
    "\n",
    "        Returns:\n",
    "            list: combinations of different parameters.\n",
    "        \"\"\"\n",
    "        self.parameters = allParams(self.m)\n",
    "        self.param_keys = list(self.parameters)\n",
    "        \n",
    "        param_list = list(itertools.product(*self.parameters.values()))        \n",
    "        return param_list\n",
    "\n",
    "\n",
    "    def kTkV(self):\n",
    "        \"\"\"initiaties the kTkV training setting. Selects a model parameters, then sends the data to train_kTkV to start the training process.\n",
    "        \"\"\"\n",
    "\n",
    "        validate_performances = []\n",
    "        validate_performances_MAE = []\n",
    "\n",
    "        test_performances = []\n",
    "        test_performances_MAE = []\n",
    "\n",
    "        train_performances = []\n",
    "        train_performances_MAE = []\n",
    "\n",
    "        models = []\n",
    "\n",
    "        param_list = self.get_params_()\n",
    "\n",
    "        for self.curr_param in tqdm(param_list, \"params\"):\n",
    "            self.features_init()\n",
    "            # print(\"features initialized\")\n",
    "            self.model = self.get_model(self.m, self.curr_param)\n",
    "\n",
    "            train_performance, validate_performance, test_performance, train_performance_MAE, validate_performance_MAE, test_performance_MAE, model = self.train_kTkV()\n",
    "            # print(\"got performances\")\n",
    "            train_performances.append(train_performance)\n",
    "            train_performances_MAE.append(train_performance_MAE)\n",
    "\n",
    "            validate_performances.append(validate_performance)\n",
    "            validate_performances_MAE.append(validate_performance_MAE)\n",
    "\n",
    "            test_performances.append(test_performance)\n",
    "            test_performances_MAE.append(test_performance_MAE)\n",
    "            \n",
    "            self.feature_close()\n",
    "            models.append(model)\n",
    "            # break \n",
    "        \n",
    "        self.feature_f.close()\n",
    "\n",
    "        train_performance_ranking = sp.rankdata(train_performances)\n",
    "        val_performance_ranking = sp.rankdata(validate_performances)\n",
    "        test_performance_ranking = sp.rankdata(test_performances)\n",
    "\n",
    "\n",
    "        self.dataframe = {\n",
    "\n",
    "            \"train performance RMSE\" : train_performances,\n",
    "            \"test performance RMSE\" : test_performances,\n",
    "            \"validate performance RMSE\" : validate_performances,\n",
    "\n",
    "            \"train performance MAE\" : train_performances_MAE,\n",
    "            \"validate performance MAE\" : validate_performances_MAE,\n",
    "            \"test performance MAE\" : test_performances_MAE,\n",
    "\n",
    "            \"train rank\" : train_performance_ranking,\n",
    "            \"validate rank\" : val_performance_ranking,\n",
    "            \"test rank\" : test_performance_ranking,\n",
    "            \n",
    "            \"max depth\" : '' if self.m == \"SVR\" else max([estimator.tree_.max_depth for estimator in model[-1].estimators_])\n",
    "\n",
    "\n",
    "        }\n",
    "        self.dataframe[\"'|'\".join(list(self.parameters))] = param_list\n",
    "        self.cv_results_ = pd.DataFrame.from_dict(self.dataframe)\n",
    "\n",
    "\n",
    "    def normal_CV(self):\n",
    "        \"\"\"Initiates the training setting for normal Cross Validation. Uses validate_kTkV for training.\n",
    "        \"\"\"\n",
    "\n",
    "        train_performances = []\n",
    "        test_performances = []\n",
    "\n",
    "        train_performances_MAE = []\n",
    "        test_performances_MAE = []\n",
    "\n",
    "        param_list = self.get_params_()\n",
    "\n",
    "        def train_loop():\n",
    "            print(\"we entered training loop\")\n",
    "            for self.curr_param in tqdm(param_list, desc = \"params\"):\n",
    "                # print(\"we here\")\n",
    "                train_performance_MSE, test_performance_MSE, train_performance_MAE, test_performance_MAE, model  = self.validate(self.data, self.outputs, kf)\n",
    "                train_performances.append(train_performance_MSE)\n",
    "                test_performances.append(test_performance_MSE)\n",
    "\n",
    "                train_performances_MAE.append(train_performance_MAE)\n",
    "                test_performances_MAE.append(test_performance_MAE)\n",
    "\n",
    "        \n",
    "            train_performance_rankings_MSE = sp.rankdata(train_performances)\n",
    "            test_performance_rankings_MSE = sp.rankdata(test_performances)\n",
    "\n",
    "            train_performance_rankings_MAE = sp.rankdata(train_performances_MAE)\n",
    "            test_performance_rankings_MAE = sp.rankdata(test_performances_MAE)\n",
    "\n",
    "\n",
    "            self.dataframe = {\n",
    "                \"train RMSE\" : train_performances,\n",
    "                \"train RMSE rank\" : train_performance_rankings_MSE,\n",
    "\n",
    "                \"test RMSE\" : test_performances,\n",
    "                \"test RMSE rank\" : test_performance_rankings_MSE,\n",
    "\n",
    "                \"train MAE\" : train_performances_MAE,\n",
    "                \"train MAE rank\" : train_performance_rankings_MAE,\n",
    "\n",
    "                \"test MAE\" : test_performances_MAE,\n",
    "                \"test MAE rank\" : test_performance_rankings_MAE,\n",
    "                \n",
    "                \"max depth\" : '' if self.m == \"SVR\" else max([estimator.tree_.max_depth for estimator in model.estimators_])\n",
    "            }\n",
    "\n",
    "            self.dataframe[\"'|'\".join(list(self.parameters))] = param_list\n",
    "            self.cv_results_ = pd.DataFrame.from_dict(self.dataframe)\n",
    "\n",
    "        if self.same_split:\n",
    "            if self.stratified != True:\n",
    "                kf = KFold(n_splits=self.CV_(), shuffle = False)\n",
    "            else:\n",
    "                kf = StratifiedKFold(n_splits=self.CV_(), shuffle = False)\n",
    "                if self.cv == \"LOO\":\n",
    "                    kf = KFold(n_splits=self.CV_(), shuffle=True) #change this later\n",
    "\n",
    "        else:\n",
    "            kf = None\n",
    "            \n",
    "        train_loop()\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"Based on training setting, this redirects training to one of the initializers.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cv != \"kTkV\":\n",
    "            if self.metric != \"all-metrics\":\n",
    "                self.oneMetric_cv()\n",
    "            elif self.metric == \"all-metrics\":\n",
    "                # print(\"all metric CV\")\n",
    "                self.normal_CV()\n",
    "    \n",
    "        else:   \n",
    "            self.kTkV()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading resting state data\n",
      "path =  /Users/saurav/Desktop/Margrit/MRI/RS/time_series\n",
      "data shape =  (55, 1128)\n",
      "outputs shape =  (55,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "params:   3%|â–Ž         | 2/75 [01:00<36:43, 30.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p2/17j674213qv7q4cbzhk97jch0000gn/T/ipykernel_28282/835194159.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAugmentation_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p2/17j674213qv7q4cbzhk97jch0000gn/T/ipykernel_28282/2608289978.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# self.feature_f.close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p2/17j674213qv7q4cbzhk97jch0000gn/T/ipykernel_28282/2608289978.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, augmentation_settings)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Check for stratified sampling part later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p2/17j674213qv7q4cbzhk97jch0000gn/T/ipykernel_28282/2608289978.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkTkV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p2/17j674213qv7q4cbzhk97jch0000gn/T/ipykernel_28282/2608289978.py\u001b[0m in \u001b[0;36mkTkV\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0mtrain_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_performance_MAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_performance_MAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_performance_MAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_kTkV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m             \u001b[0;31m# print(\"got performances\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mtrain_performances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_performance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p2/17j674213qv7q4cbzhk97jch0000gn/T/ipykernel_28282/2608289978.py\u001b[0m in \u001b[0;36mtrain_kTkV\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# print('data split here')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0mtrain_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_performance_MAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_performance_MAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0;31m# print(\"got performances\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p2/17j674213qv7q4cbzhk97jch0000gn/T/ipykernel_28282/2608289978.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, data, outputs, kf2)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0mtrain_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# print(\"validate shape = \", X_validate.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                                         indices=indices)\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \"\"\"\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1253\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDOUBLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_sample_weight\u001b[0;34m(sample_weight, X, dtype, copy)\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m         sample_weight = check_array(\n\u001b[0m\u001b[1;32m   1377\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;31m# store whether originally we wanted numeric dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m     \u001b[0mdtype_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"numeric\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0mdtype_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Augmentation_settings = {\n",
    "    \"Cross Validation Type\": \"kTkV\",\n",
    "    \"model\" : \"RF\",\n",
    "    \"metric\" : \"all-metrics\", # not required anymore\n",
    "\n",
    "    \"Augment\" : False, # not implemented yet\n",
    "    # \"transform\" : True, # need to implement this now. \n",
    "\n",
    "    \"verbose\" : 0,    # dont change this. Taken care of \n",
    "    \"top_k\" : 150,\n",
    "\n",
    "    \"repeat features\" : False,\n",
    "    \"same split\" :  False, #implement false condition\n",
    "    \n",
    "    \"stratified\" : False,\n",
    "    \"data\" : \"RS\",\n",
    "    \n",
    "    \"feature reduction\" : \"pearson\",\n",
    "    \"features reduced per step\" : 1\n",
    "    # \"order\" : args.order if 'stratified' in args else None, #implement false condition\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = Model(Augmentation_settings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(corrs.values[-1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import heapq\n",
    "\n",
    "# test_top_cols = heapq.nlargest(150, range(len(importances)), importances.take)\n",
    "\n",
    "# test_top_cols.sort()\n",
    "# top_columns.sort()\n",
    "# # test_top_cols\n",
    "\n",
    "importances.take"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1119</th>\n",
       "      <th>1120</th>\n",
       "      <th>1121</th>\n",
       "      <th>1122</th>\n",
       "      <th>1123</th>\n",
       "      <th>1124</th>\n",
       "      <th>1125</th>\n",
       "      <th>1126</th>\n",
       "      <th>1127</th>\n",
       "      <th>1128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.360065</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.054958</td>\n",
       "      <td>0.266475</td>\n",
       "      <td>0.232611</td>\n",
       "      <td>-0.338867</td>\n",
       "      <td>0.631779</td>\n",
       "      <td>-0.359282</td>\n",
       "      <td>-0.410621</td>\n",
       "      <td>-0.126857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102267</td>\n",
       "      <td>0.071445</td>\n",
       "      <td>0.572910</td>\n",
       "      <td>0.096260</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>0.054751</td>\n",
       "      <td>-0.027064</td>\n",
       "      <td>0.266298</td>\n",
       "      <td>-0.134463</td>\n",
       "      <td>87.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.185745</td>\n",
       "      <td>0.159007</td>\n",
       "      <td>-0.080865</td>\n",
       "      <td>-0.160646</td>\n",
       "      <td>-0.047338</td>\n",
       "      <td>0.138317</td>\n",
       "      <td>0.461644</td>\n",
       "      <td>0.318556</td>\n",
       "      <td>0.088526</td>\n",
       "      <td>-0.203324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251529</td>\n",
       "      <td>-0.040121</td>\n",
       "      <td>0.591814</td>\n",
       "      <td>0.084357</td>\n",
       "      <td>0.088996</td>\n",
       "      <td>-0.136049</td>\n",
       "      <td>0.073134</td>\n",
       "      <td>0.295827</td>\n",
       "      <td>-0.101401</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000432</td>\n",
       "      <td>-0.106150</td>\n",
       "      <td>0.111955</td>\n",
       "      <td>0.033202</td>\n",
       "      <td>0.061812</td>\n",
       "      <td>0.090680</td>\n",
       "      <td>0.145437</td>\n",
       "      <td>-0.058595</td>\n",
       "      <td>-0.129418</td>\n",
       "      <td>-0.399258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148758</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.243912</td>\n",
       "      <td>-0.075932</td>\n",
       "      <td>0.037224</td>\n",
       "      <td>0.024014</td>\n",
       "      <td>0.164834</td>\n",
       "      <td>0.163829</td>\n",
       "      <td>0.143013</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.066249</td>\n",
       "      <td>0.105581</td>\n",
       "      <td>-0.195710</td>\n",
       "      <td>-0.257786</td>\n",
       "      <td>-0.055454</td>\n",
       "      <td>-0.130789</td>\n",
       "      <td>0.770839</td>\n",
       "      <td>0.209555</td>\n",
       "      <td>-0.084566</td>\n",
       "      <td>-0.312965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302855</td>\n",
       "      <td>0.430871</td>\n",
       "      <td>0.405293</td>\n",
       "      <td>0.045807</td>\n",
       "      <td>0.209190</td>\n",
       "      <td>0.094675</td>\n",
       "      <td>-0.078121</td>\n",
       "      <td>0.682280</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>74.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047168</td>\n",
       "      <td>0.040613</td>\n",
       "      <td>-0.066341</td>\n",
       "      <td>-0.095488</td>\n",
       "      <td>-0.215614</td>\n",
       "      <td>0.012098</td>\n",
       "      <td>0.140075</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>-0.067715</td>\n",
       "      <td>-0.029938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257647</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.504215</td>\n",
       "      <td>-0.046846</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.150161</td>\n",
       "      <td>-0.164306</td>\n",
       "      <td>0.597433</td>\n",
       "      <td>-0.112093</td>\n",
       "      <td>30.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -0.360065 -0.007469  0.054958  0.266475  0.232611 -0.338867  0.631779   \n",
       "1  0.185745  0.159007 -0.080865 -0.160646 -0.047338  0.138317  0.461644   \n",
       "2 -0.000432 -0.106150  0.111955  0.033202  0.061812  0.090680  0.145437   \n",
       "3 -0.066249  0.105581 -0.195710 -0.257786 -0.055454 -0.130789  0.770839   \n",
       "4  0.047168  0.040613 -0.066341 -0.095488 -0.215614  0.012098  0.140075   \n",
       "\n",
       "       7         8         9     ...      1119      1120      1121      1122  \\\n",
       "0 -0.359282 -0.410621 -0.126857  ...  0.102267  0.071445  0.572910  0.096260   \n",
       "1  0.318556  0.088526 -0.203324  ...  0.251529 -0.040121  0.591814  0.084357   \n",
       "2 -0.058595 -0.129418 -0.399258  ... -0.148758  0.048900  0.243912 -0.075932   \n",
       "3  0.209555 -0.084566 -0.312965  ...  0.302855  0.430871  0.405293  0.045807   \n",
       "4  0.207200 -0.067715 -0.029938  ...  0.257647  0.006619  0.504215 -0.046846   \n",
       "\n",
       "       1123      1124      1125      1126      1127  1128  \n",
       "0  0.013795  0.054751 -0.027064  0.266298 -0.134463  87.2  \n",
       "1  0.088996 -0.136049  0.073134  0.295827 -0.101401  25.2  \n",
       "2  0.037224  0.024014  0.164834  0.163829  0.143013  52.0  \n",
       "3  0.209190  0.094675 -0.078121  0.682280  0.009166  74.1  \n",
       "4 -0.000666 -0.150161 -0.164306  0.597433 -0.112093  30.8  \n",
       "\n",
       "[5 rows x 1129 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = outputs.flatten()\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def important_columns(data, outputs, num_features): \n",
    "    \"\"\"This function finds the names of important features in the data, either based on two factors\n",
    "        - Pearson Correlation with WAB scores \n",
    "        - Recurrent Feature Elimination (RFE)\n",
    "\n",
    "    Args:\n",
    "        data (numpy array): Input data without output column\n",
    "        outputs (numpy array): 1D array of WAB scores / any other output\n",
    "\n",
    "    Returns:\n",
    "        numpy array : finds the column index numbers and returns it \n",
    "    \"\"\"    \n",
    "\n",
    "    outputs = outputs.reshape(outputs.shape[0], 1)\n",
    "    data = np.hstack((data, outputs))\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    corrs = data.corr().abs()\n",
    "    importances = corrs.values[-1][:-1]\n",
    "\n",
    "    top_columns = np.argpartition(importances, -num_features)[-num_features:]\n",
    "    return top_columns\n",
    "\n",
    "def reduce_data( data, top_columns):\n",
    "    \"\"\"filter important columns from the input data\n",
    "\n",
    "    Args:\n",
    "        data (numpy array): Input data without output columns\n",
    "\n",
    "    Returns:\n",
    "        numpy array: Input data with selected top features\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.DataFrame(data)\n",
    "    data = data.iloc[:,top_columns]\n",
    "    return data.values\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.values\n",
    "# data = data[:,:-1]\n",
    "data2 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62.8775271  54.88075783 57.47601334 59.65109178 69.44145882]  --  21.441909466093673\n",
      "[53.46994776 57.41393091 65.89395901 68.84652212 69.37231472]  --  21.521391759865427\n",
      "[62.01827608 60.58096351 67.89312279 68.89568014 69.38485639]  --  28.89929220535707\n",
      "[69.24179185 63.92448064 62.98333279 65.3905103  70.14190337]  --  28.975892760547104\n",
      "[75.99682532 67.75055461 69.39321837 82.03643542 59.97585907]  --  17.316080966391137\n",
      "[59.0003309  62.6137666  50.97141126 81.02389895 71.55495703]  --  24.40554859589116\n",
      "[65.49623452 64.95465626 70.10976615 65.15957619 63.91266977]  --  23.374218340396485\n",
      "[67.50033243 72.92022438 73.15172227 66.69538247 79.690335  ]  --  19.427007203423297\n",
      "[56.8182744  67.93612582 75.36565606 68.02549464 58.68802928]  --  16.678809835741774\n",
      "[71.37754764 70.49590017 72.43324831 76.37256812 67.41045608]  --  29.559888127231616\n",
      "[70.84167949 66.96301448 64.77157511 72.48024486 59.95053366]  --  13.836128534346118\n",
      "mean rmse =  22.312378890480442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=11, shuffle = True)\n",
    "\n",
    "num_features = 25\n",
    "total , count = 0,0\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 30,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"learning_rate\": 0.00001,\n",
    "    \"loss\": \"ls\",\n",
    "}\n",
    "top_columns = important_columns(data, outputs, num_features)\n",
    "X_train = reduce_data(data, top_columns)\n",
    "\n",
    "for train_index, validate_index in kf.split(data, outputs):\n",
    "    X_train, X_test, y_train, y_test = data[train_index], data[validate_index], outputs[train_index], outputs[validate_index] \n",
    "    # top_columns = important_columns(X_train, y_train, num_features)\n",
    "    # X_train = reduce_data(X_train, top_columns)\n",
    "    # X_test = reduce_data(X_test, top_columns)\n",
    " \n",
    "    # kernel = DotProduct() + WhiteKernel()\n",
    "    \n",
    "    # m1 = GaussianProcessRegressor(kernel=kernel, random_state=0)\n",
    "    # m1 = ensemble.GradientBoostingRegressor(**params)   \n",
    "    # m1 = AdaBoostRegressor(RandomForestRegressor(max_depth=5, random_state=0))\n",
    "    \n",
    "    m1 = AdaBoostRegressor(SVR(kernel = \"linear\", C=1, epsilon=10, tol=0.01, gamma=1e-3))\n",
    "    model = make_pipeline(StandardScaler(), m1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_outputs = model.predict(X_test)\n",
    "    mse = mean_squared_error(test_outputs, y_test, squared=False)\n",
    "    \n",
    "    total+=mse \n",
    "    count+=1\n",
    "    \n",
    "    print(test_outputs, \" -- \", mse)\n",
    "    # print(y_test)\n",
    "\n",
    "print(\"mean rmse = \", float(total/count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
